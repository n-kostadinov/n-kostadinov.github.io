<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Favicon Icon -->
    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.png">

    <title>Model Stack, Part 1 of Cat vs Dog Real-Time Classification Series</title>
    <meta name="description"
          content="This post is the first of a series of three. The goal is to embed a neural network into a real time web application for image classification. In this first p...">

    <link rel="canonical" href="http://machinememos.com/python/catdog/artificial%20intelligence/machine%20learning/neural%20networks/convolutional%20neural%20network/googlelenet/inception/xgboost/ridgeregression/sklearn/tensorflow/image%20classification/imagenet/apache%20kafka/real-time/2017/05/18/catdog-stacked-classification.html">
    <link rel="alternate" type="application/rss+xml" title="Blog" href="http://machinememos.com/feed.xml">

    <script type="text/javascript" src="/bower_components/jquery/dist/jquery.min.js"></script>

    <!-- Third-Party CSS -->
    <link rel="stylesheet" href="/bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="/bower_components/octicons/octicons/octicons.css">
    <link rel="stylesheet" href="/bower_components/hover/css/hover-min.css">
    <link rel="stylesheet" href="/bower_components/primer-markdown/dist/user-content.min.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- My CSS -->
    <link rel="stylesheet" href="/assets/css/common.css">

    <!-- CSS set in page -->
    

    <!-- CSS set in layout -->
    
    <link rel="stylesheet" href="/assets/css/sidebar-post-nav.css">
    

    <script type="text/javascript" src="/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>

</head>


    <body>

    <header class="site-header">
    <div class="container">
        <a id="site-header-brand" href="/" title="MACHINE MEMOS">
			<div class="media">
    			<span class="media-left">
        			<img src="/assets/images/machine_memos_logo.svg" onerror="this.onerror=null; this.src='/assets/images/machine_memos_logo.png'" class="img-responsive" style="max-width: 1em;">
    			</span>
    			<div class="media-body" style="max-width:9em; vertical-align: middle;">
        			MACHINE MEMOS
				</div>
			</div>
			</a>
        <nav class="site-header-nav" role="navigation">
            
            <a href="/"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="BLOG">
                BLOG
            </a>
            
            <a href="/code"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="CODE">
                CODE
            </a>
            
            <a href="/timeline"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="TIMELINE">
                TIMELINE
            </a>
            
            <a href="/about"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="ABOUT">
                ABOUT
            </a>
            
        </nav>
    </div>
</header>


        <div class="content">
            <section class="jumbotron geopattern" data-pattern-id="Model Stack, Part 1 of Cat vs Dog Real-Time Classification Series">
    <div class="container">
        <div id="jumbotron-meta-info">
            <h1>Model Stack, Part 1 of Cat vs Dog Real-Time Classification Series</h1>
            <span class="meta-info">
                
                 
                <span class="octicon octicon-calendar"></span> 2017/05/18
                
				
					by Nikolay Kostadinov
				
            </span>
        </div>
    </div>
</section>
<script>
    $(document).ready(function(){

        $('.geopattern').each(function(){
            $(this).geopattern($(this).data('pattern-id'), {color:"#337ab7"});
        });

    });
</script>
<article class="post container" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="row">

        
        <div class="col-md-8 markdown-body">

            <p>This post is the first of a series of three. The goal is to embed a neural network into a real time web application for image classification. In this first part, I will go through the data and create the machine learning model.</p>

<h1 id="real-time-prediction">Real-time prediction</h1>
<p>In my previous posts I showed different approaches on classifying images through neural networks. You may choose to create a neural network from scratch <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/dropout/image%20classification/2017/04/23/convolutional-neural-network-from-scratch.html">Convolutional neural network for image classification from scratch</a> or you prefer to use a pre-trained neural network like <a href="https://arxiv.org/abs/1409.4842">Google’s Inception</a> as demonstrated in <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/tensorflow/dropout/image%20classification/2017/05/04/cnn-image-classification-cifar-10-inceptionV3.html">Image classification with pre-trained CNN InceptionV3</a> and <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/xgboost/ridgeregression/sklearn/tensorflow/image%20classification/imagenet/2017/05/11/cnn-image-classification-cifar-10-stacked-inceptionV3.html">Image classification with stacked InceptionV3</a>. Anyway, shortly after blogging about using stacked models for image classification I received a comment from a friend working in the Big Data department of a commercial bank in the Netherlands. What he wanted to see is how the machine learning scripts could be integrated into their existing Big Data infrastructure that is largely based on real-time communication with <a href="https://kafka.apache.org/">Apache Kafka</a>. A few days later, a friend working for the hedge fund industry in London called. He is currently prototyping different trading models with <a href="https://www.r-project.org/">R Statistics</a>. He was interested in how one could combine the predictive power of tens, possibly hundreds of R scripts und use these for real-time trading. Well, coming from the software engineering part of the computer science word and having worked in the Java Enterprise domain for several years now, I decided to write a series of posts and demonstrate how one could integrate a model stack and use it in real-time.</p>

<p>In this first post of the series, I will create a model stack consisting of <a href="https://arxiv.org/abs/1512.00567">Google’s InceptionV3</a> and a second classification model. Hence, what I will do here is very similar to my previous post <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/xgboost/ridgeregression/sklearn/tensorflow/image%20classification/imagenet/2017/05/11/cnn-image-classification-cifar-10-stacked-inceptionV3.html">Image classification with stacked InceptionV3</a>. In part 2 of this series I will show how one can use the model stack to create a predictive kafka service. In part 3, I will show you how you can quickly start kafka and build a web application that utilizes the predictive service in real-time.</p>

<p>The smart pipeline that I am going to build here can be used in finance and many other industries. However, comprehensive financial data is not very visually appealing and not that fun. So I will be building an online real-time Cat vs Dog image classifier. In this first post we will train the models and build the classifier.</p>

<h2 id="preparing-the-cat--dog-dataset">Preparing the cat &amp; dog dataset</h2>

<p>I am going to use the training set provided in the last <a href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition">Cat vs Dog Kaggle competition</a>. It consists of 25,000 images of cats and dogs. Downloading the dataset from script is a bit problematic, as you have to agree with the competition’s rules to be able to download. Assuming, you manually downloaded the training set and unzipped it in a directory called image_data you start by reading all image paths like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c">## read addresses and labels from the 'train' folder</span>
<span class="n">image_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s">'image_data/*.jpg'</span><span class="p">)</span>

<span class="c">## Create labels 0 = Cat and 1 = Dog</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="s">'cat'</span> <span class="ow">in</span> <span class="n">image_path</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="n">image_paths</span><span class="p">]</span>  

<span class="n">training_set</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">image_paths</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>

<span class="n">shuffle</span><span class="p">(</span><span class="n">training_set</span><span class="p">)</span>
</code></pre>
</div>

<p>Next, the images have to be converted to Tensorflow Records (tfrecords). If you take a look at the images, you will notice that they have fairly arbitrary sizes and aspect ratios. While converting the images, you will definitely want to resize these to the input size required by the neural network, that is 299 x 299 pixels. This way you will save on both disk space (most of the images are larger than 299 x 299) and compute time while training as no resizing will be needed. While converting you may also want to print out the first few images and make sure they look ok.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="kn">as</span> <span class="nn">mpimg</span>
               
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">IMAGE_SIZE</span> <span class="o">=</span> <span class="mi">299</span>
<span class="n">TRAIN_SET_FILE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'tfrecord'</span><span class="p">,</span> <span class="s">'train'</span><span class="p">)</span>
<span class="n">TRAINING_SET_SIZE</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_set</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">bytes_feature</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span><span class="n">bytes_list</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">BytesList</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="n">value</span><span class="p">]))</span>

<span class="k">def</span> <span class="nf">int64_feature</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span><span class="n">int64_list</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Int64List</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="n">value</span><span class="p">]))</span>

<span class="k">def</span> <span class="nf">to_example</span><span class="p">(</span><span class="n">png_image_data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
     <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Example</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Features</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="p">{</span>
          <span class="s">'image/encoded'</span><span class="p">:</span> <span class="n">bytes_feature</span><span class="p">(</span><span class="n">png_image_data</span><span class="p">),</span>
          <span class="s">'image/format'</span><span class="p">:</span> <span class="n">bytes_feature</span><span class="p">(</span><span class="s">'png'</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)),</span>
          <span class="s">'image/height'</span><span class="p">:</span> <span class="n">int64_feature</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">),</span>
          <span class="s">'image/width'</span><span class="p">:</span> <span class="n">int64_feature</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">),</span>
          <span class="s">'image/class/label'</span><span class="p">:</span> <span class="n">int64_feature</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="p">}))</span>

<span class="k">def</span> <span class="nf">log_image</span><span class="p">(</span><span class="n">png_image_string</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'sample.png'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">png_image_string</span><span class="p">)</span>
    <span class="n">img</span><span class="o">=</span><span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">'sample.png'</span><span class="p">)</span>
    <span class="n">imgplot</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s">'sample.png'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_tfrecord</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">tfrecrod_file_name</span><span class="p">):</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">python_io</span><span class="o">.</span><span class="n">TFRecordWriter</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tfrecrod_file_name</span><span class="p">))</span> <span class="k">as</span> <span class="n">tfrecord_writer</span><span class="p">:</span>
        
        <span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
        
        <span class="n">image_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">IMAGE_SIZE</span><span class="p">,</span><span class="n">IMAGE_SIZE</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        
        <span class="n">image_path_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">)</span>
        <span class="n">file_contents</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">image_path_placeholder</span><span class="p">)</span>
        <span class="n">image_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">decode_jpeg</span><span class="p">(</span><span class="n">file_contents</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">resized_image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize_images</span><span class="p">(</span><span class="n">image_data</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)</span>
        <span class="n">png_image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">encode_png</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">resized_image</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

            <span class="c">## Initializing the variables</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">TRAINING_SET_SIZE</span><span class="p">)):</span>                
                <span class="n">image_path</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">png_image_string</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">png_image</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">image_path_placeholder</span><span class="p">:</span> <span class="n">image_path</span><span class="p">})</span>
                <span class="n">example</span> <span class="o">=</span> <span class="n">to_example</span><span class="p">(</span><span class="n">png_image_string</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
                
                <span class="n">tfrecord_writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
                <span class="c">## Show first 10 images</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
                    <span class="n">log_image</span><span class="p">(</span><span class="n">png_image_string</span><span class="p">)</span>



<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s">'tfrecord'</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s">'tfrecord'</span><span class="p">)</span>
    <span class="n">create_tfrecord</span><span class="p">(</span><span class="n">training_set</span><span class="p">,</span> <span class="n">TRAIN_SET_FILE</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 0/25000 [00:00&lt;?, ?it/s]
</code></pre>
</div>

<p><img src="/assets/images/output_3_1.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 1/25000 [00:00&lt;2:08:11,  3.25it/s]
</code></pre>
</div>

<p><img src="/assets/images/output_3_3.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 2/25000 [00:00&lt;2:13:32,  3.12it/s]
</code></pre>
</div>

<p><img src="/assets/images/output_3_5.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 3/25000 [00:00&lt;2:11:24,  3.17it/s]
</code></pre>
</div>

<p><img src="/assets/images/output_3_7.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 4/25000 [00:01&lt;2:12:23,  3.15it/s]
</code></pre>
</div>

<p><img src="/assets/images/output_3_9.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 5/25000 [00:01&lt;2:12:48,  3.14it/s]
</code></pre>
</div>

<p><img src="/assets/images/output_3_11.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 6/25000 [00:01&lt;2:14:21,  3.10it/s]
</code></pre>
</div>

<p><img src="/assets/images/output_3_13.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 7/25000 [00:02&lt;2:15:07,  3.08it/s]
</code></pre>
</div>

<p><img src="/assets/images/output_3_15.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 8/25000 [00:02&lt;2:13:21,  3.12it/s]
</code></pre>
</div>

<p><img src="/assets/images/output_3_17.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 9/25000 [00:02&lt;2:17:16,  3.03it/s]
</code></pre>
</div>

<p><img src="/assets/images/output_3_19.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>100%|██████████| 25000/25000 [21:13&lt;00:00, 19.63it/s]  
</code></pre>
</div>

<h2 id="preparing-inceptionv3">Preparing InceptionV3</h2>
<p>In my previous post I was able to reach fairly good results when classifying images from the Cifar-10 dataset by using the InceptionV3 convolutional neural network (CNN). Here are few lines of code to directly download the InceptionV3 weights of the neural network.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c">## DOWNLOAD DATASET </span>
<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">tarfile</span>

<span class="n">inceptionv3_archive</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'model'</span><span class="p">,</span> <span class="s">'inception_v3_2016_08_28.tar.gz'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DLProgress</span><span class="p">(</span><span class="n">tqdm</span><span class="p">):</span>
    <span class="n">last_block</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">=</span> <span class="n">total_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">block_num</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span> <span class="o">=</span> <span class="n">block_num</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s">'model'</span><span class="p">):</span>
    <span class="c">## create directory to store model</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s">'model'</span><span class="p">)</span>
    <span class="c">## download the model</span>
    <span class="k">with</span> <span class="n">DLProgress</span><span class="p">(</span><span class="n">unit</span><span class="o">=</span><span class="s">'B'</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s">'InceptionV3'</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">urlretrieve</span><span class="p">(</span>
            <span class="c">## I hope this url stays there</span>
            <span class="s">'http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz'</span><span class="p">,</span>
            <span class="n">inceptionv3_archive</span><span class="p">,</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">hook</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">inceptionv3_archive</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s">'model'</span><span class="p">)</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>InceptionV3: 101MB [00:55, 1.83MB/s]                              
</code></pre>
</div>

<h2 id="using-inceptionv3-as-first-level-classifier">Using InceptionV3 as first level classifier</h2>
<p>Here are a couple of functions for preparing the dataset and loading a batch.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">inception_preprocessing</span>

<span class="k">def</span> <span class="nf">load_batch</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">data_provider</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">dataset_data_provider</span><span class="o">.</span><span class="n">DatasetDataProvider</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span> <span class="n">common_queue_capacity</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">common_queue_min</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">image_raw</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">data_provider</span><span class="o">.</span><span class="n">get</span><span class="p">([</span><span class="s">'image'</span><span class="p">,</span> <span class="s">'label'</span><span class="p">])</span>
    
    <span class="c">## Preprocess image for usage by Inception.</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">inception_preprocessing</span><span class="o">.</span><span class="n">preprocess_image</span><span class="p">(</span>
        <span class="n">image_raw</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="n">is_training</span><span class="p">)</span>
    
    <span class="c">## Preprocess the image for display purposes.</span>
    <span class="n">image_raw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image_raw</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">image_raw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize_images</span><span class="p">(</span><span class="n">image_raw</span><span class="p">,</span> <span class="p">[</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">])</span>
    <span class="n">image_raw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image_raw</span><span class="p">)</span>

    <span class="c">## Batch it up.</span>
    <span class="n">images</span><span class="p">,</span> <span class="n">images_raw</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
          <span class="p">[</span><span class="n">image</span><span class="p">,</span> <span class="n">image_raw</span><span class="p">,</span> <span class="n">label</span><span class="p">],</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
          <span class="n">num_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">capacity</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">images</span><span class="p">,</span> <span class="n">images_raw</span><span class="p">,</span> <span class="n">labels</span>

<span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="n">dataset_file_name</span><span class="p">,</span> <span class="n">train_sample_size</span><span class="p">):</span>

    <span class="n">keys_to_features</span> <span class="o">=</span> <span class="p">{</span>
          <span class="s">'image/encoded'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">((),</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="s">''</span><span class="p">),</span>
          <span class="s">'image/format'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">((),</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="s">'png'</span><span class="p">),</span>
          <span class="s">'image/class/label'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">(</span>
              <span class="p">[],</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)),</span>
    <span class="p">}</span>

    <span class="n">items_to_handlers</span> <span class="o">=</span> <span class="p">{</span>
          <span class="s">'image'</span><span class="p">:</span> <span class="n">slim</span><span class="o">.</span><span class="n">tfexample_decoder</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span>
          <span class="s">'label'</span><span class="p">:</span> <span class="n">slim</span><span class="o">.</span><span class="n">tfexample_decoder</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="s">'image/class/label'</span><span class="p">),</span>
    <span class="p">}</span>
    
    <span class="n">ITEMS_TO_DESCRIPTIONS</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'image'</span><span class="p">:</span> <span class="s">'A [299 x 299 x 3] color image.'</span><span class="p">,</span>
        <span class="s">'label'</span><span class="p">:</span> <span class="s">'A single integer that is 0 or 1 for cat and dog'</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">decoder</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">tfexample_decoder</span><span class="o">.</span><span class="n">TFExampleDecoder</span><span class="p">(</span><span class="n">keys_to_features</span><span class="p">,</span> <span class="n">items_to_handlers</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">slim</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span>
          <span class="n">data_sources</span><span class="o">=</span><span class="n">dataset_file_name</span><span class="p">,</span>
          <span class="n">reader</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">TFRecordReader</span><span class="p">,</span>
          <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
          <span class="n">num_samples</span><span class="o">=</span><span class="n">train_sample_size</span><span class="p">,</span>
          <span class="n">items_to_descriptions</span><span class="o">=</span><span class="n">ITEMS_TO_DESCRIPTIONS</span><span class="p">,</span>
          <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="c">## cat and dog</span>
          <span class="n">labels_to_names</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s">'cat'</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="s">'dog'</span><span class="p">})</span>
</code></pre>
</div>

<p>Same as in <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/xgboost/ridgeregression/sklearn/tensorflow/image%20classification/imagenet/2017/05/11/cnn-image-classification-cifar-10-stacked-inceptionV3.html">Image classification with stacked InceptionV3</a> we are going to use InceptionV3 as a first level classifier in a stack of classifiers consisting of two levels. In the code below the InceptionV3 model is loaded and without any training whatsoever it is used to make a prediction for all images in the training set. Note that the unmodified InceptionV3 model has an output that is a vector of length 1001. For each image this output vector is saved to be later used as un input for the second level classifier.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">inception_v3</span> <span class="kn">import</span> <span class="n">inception_v3</span>
<span class="kn">from</span> <span class="nn">inception_v3</span> <span class="kn">import</span> <span class="n">inception_v3_arg_scope</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">NUMBER_OF_STEPS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">TRAINING_SET_SIZE</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">INCEPTION_OUTPUT_SIZE</span> <span class="o">=</span> <span class="mi">1001</span>

<span class="n">INCEPTION_MODEL_FILE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'model'</span><span class="p">,</span><span class="s">'inception_v3.ckpt'</span><span class="p">)</span>

<span class="n">slim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">slim</span>

<span class="n">meta_data_train_X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">meta_data_train_Y</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
    
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">TRAIN_SET_FILE</span><span class="p">,</span> <span class="n">TRAINING_SET_SIZE</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">images_raw</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_batch</span><span class="p">(</span>
      <span class="n">train_dataset</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="n">IMAGE_SIZE</span><span class="p">)</span>
    
<span class="c">## Create the model, use the default arg scope to configure the batch norm parameters.</span>
<span class="k">with</span> <span class="n">slim</span><span class="o">.</span><span class="n">arg_scope</span><span class="p">(</span><span class="n">inception_v3_arg_scope</span><span class="p">()):</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">inception_v3</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">INCEPTION_OUTPUT_SIZE</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">probabilities</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    
<span class="n">init_fn</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">assign_from_checkpoint_fn</span><span class="p">(</span>
    <span class="n">INCEPTION_MODEL_FILE</span><span class="p">,</span> <span class="n">slim</span><span class="o">.</span><span class="n">get_model_variables</span><span class="p">())</span>
    
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">slim</span><span class="o">.</span><span class="n">queues</span><span class="o">.</span><span class="n">QueueRunners</span><span class="p">(</span><span class="n">sess</span><span class="p">):</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">initialize_local_variables</span><span class="p">())</span>
        <span class="n">init_fn</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">NUMBER_OF_STEPS</span><span class="p">)):</span>
            <span class="n">np_probabilities</span><span class="p">,</span> <span class="n">np_images_raw</span><span class="p">,</span> <span class="n">np_labels</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">images_raw</span><span class="p">,</span> <span class="n">labels</span><span class="p">])</span>
            <span class="n">meta_data_train_X</span> <span class="o">+=</span> <span class="n">np_probabilities</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">meta_data_train_Y</span> <span class="o">+=</span> <span class="n">np_labels</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>100%|██████████| 500/500 [1:42:42&lt;00:00, 13.21s/it]
</code></pre>
</div>

<p>It does not hurt to save the outputs to the disk in case the python notebook kernel crashes…</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pickle</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">)</span> <span class="o">==</span> <span class="n">TRAINING_SET_SIZE</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">meta_data_train_Y</span><span class="p">)</span> <span class="o">==</span> <span class="n">TRAINING_SET_SIZE</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'meta_data_train_inceptionV3.p'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">((</span><span class="n">meta_data_train_X</span><span class="p">,</span> <span class="n">meta_data_train_Y</span><span class="p">),</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'meta_data_train_inceptionV3.p'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
    <span class="n">meta_data_train_X</span><span class="p">,</span> <span class="n">meta_data_train_Y</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</code></pre>
</div>

<h2 id="selecting-second-level-classifier">Selecting second level classifier</h2>
<p>Once the training data set goes through the InceptionV3 network, you are all set to use the output vectors that have been produced as a training set for a second level classifier, Hence, the next task is to choose the second level classifier. As an input it receives the output vectors created by the unmodified InceptionV3 neural network. Its output, however, is the actual label - 0 for a cat and 1 for a dog. As in the <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/xgboost/ridgeregression/sklearn/tensorflow/image%20classification/imagenet/2017/05/11/cnn-image-classification-cifar-10-stacked-inceptionV3.html">Image classification with stacked InceptionV3</a> I will train three different second level classifiers in order to compare their performance. I will start with the most simple classifier possible, linear regression with L2 regularization, that is also known as ridge regression classifier. It is not a bad idea to use a 5-fold cross validation in order to evaluate the classifier’s accuracy without actually using the test set.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">ridge_classifier</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">ridge_classifier</span><span class="p">,</span> <span class="n">meta_data_train_X</span><span class="p">,</span> <span class="n">meta_data_train_Y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy ridge classifier'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Accuracy ridge classifier 0.985839999798
</code></pre>
</div>

<p>Even with the most simple second level classifier possible i.e. linear regression we get 98.58% accuracy. This is not surprising at all. There are a lot of cats and dogs in the <a href="http://www.image-net.org/">Imagenet</a> dataset that has been used by Google when training the Inception models. Let’s check if accuracy can be improved with a fully connected network. The dataset is split into a training and test set that contains 23,000 and 2,000 images respectively. The test set is needed to measure performance. After every 30 steps we print out the performance.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">[:</span><span class="mi">23000</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">meta_data_train_Y</span><span class="p">[:</span><span class="mi">23000</span><span class="p">]</span>
<span class="n">validation_X</span><span class="p">,</span> <span class="n">validation_Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">[</span><span class="mi">23000</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">meta_data_train_Y</span><span class="p">[</span><span class="mi">23000</span><span class="p">:]</span>

<span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">infer_real_valued_columns_from_input</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span>
<span class="n">dnnClassifier</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">DNNClassifier</span><span class="p">(</span><span class="n">hidden_units</span><span class="o">=</span><span class="p">[</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
                                            <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>  
                                            <span class="n">n_classes</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
                                            <span class="n">model_dir</span><span class="o">=</span><span class="s">'second_leveld_dnn'</span><span class="p">,</span>
                                            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
                                            <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)):</span>
    <span class="n">dnnClassifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">accuracy_score</span> <span class="o">=</span> <span class="n">dnnClassifier</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">validation_X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">validation_Y</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="s">"accuracy"</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Accuracy DNNClassifier'</span><span class="p">,</span><span class="n">accuracy_score</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>  0%|          | 0/10 [00:00&lt;?, ?it/s]/home/freeman/anaconda3/envs/machinelearning/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py:247: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.
  equality = a == b
 10%|█         | 1/10 [03:42&lt;33:26, 222.93s/it]

Accuracy DNNClassifier 0.9905


 20%|██        | 2/10 [07:22&lt;29:34, 221.87s/it]

Accuracy DNNClassifier 0.9905


 30%|███       | 3/10 [11:05&lt;25:56, 222.34s/it]

Accuracy DNNClassifier 0.991


 40%|████      | 4/10 [14:59&lt;22:34, 225.67s/it]

Accuracy DNNClassifier 0.992


 50%|█████     | 5/10 [18:39&lt;18:40, 224.16s/it]

Accuracy DNNClassifier 0.992


 60%|██████    | 6/10 [22:24&lt;14:57, 224.30s/it]

Accuracy DNNClassifier 0.991


 70%|███████   | 7/10 [26:16&lt;11:19, 226.62s/it]

Accuracy DNNClassifier 0.9915


 80%|████████  | 8/10 [30:00&lt;07:31, 225.69s/it]

Accuracy DNNClassifier 0.991


 90%|█████████ | 9/10 [33:56&lt;03:48, 228.91s/it]

Accuracy DNNClassifier 0.991


100%|██████████| 10/10 [37:30&lt;00:00, 224.40s/it]

Accuracy DNNClassifier 0.991
</code></pre>
</div>

<p>Indeed, the accuracy gets even better and reaches 99.1%. Nevertheless in <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/xgboost/ridgeregression/sklearn/tensorflow/image%20classification/imagenet/2017/05/11/cnn-image-classification-cifar-10-stacked-inceptionV3.html">Image classification with stacked InceptionV3</a> the best performance was reached by the boosted trees classifier <a href="http://xgboost.readthedocs.io/en/latest/python/python_intro.html">xgboost</a>. Let’s try it in a 5-fold cross validaiton.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">xgboost</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">xgb_classifier</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">xgb_classifier</span><span class="p">,</span>  <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_Y</span><span class="p">),</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy xgboost'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Accuracy xgboost 0.992199967875


[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.7min finished
</code></pre>
</div>

<p>And once again xgboost did not disappoint and reached the best accuracy of 99,22%. For the next part of this series I will be using xgboost as a second level classifier that makes the final decision between a cat and a dog. Therefore, xgboost is trained once again by using all the data and saved to the disk.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c">## Prepare classifier</span>
<span class="n">xgb_classifier</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_Y</span><span class="p">))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'xgboost_model.p'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">xgb_classifier</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
</code></pre>
</div>

<p>In the second part of this series I will use the small stack consisting of InceptionV3 and xgboost to create a micro service. The micro service will be subscribed to the Apache Kafka event bus and will be used for real-time image classification. As always you can checkout out the whole repo here: <a href="https://github.com/n-kostadinov/catdog-realtime-classification-kafka-service">catdog-realtime-classification-kafka-service</a></p>


            <!-- Comments -->
            
<div class="comments">
    <div id="disqus_thread"></div>
    <script>
        /**
         * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
         * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
         */
        /*
         var disqus_config = function () {
         this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
         this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
         };
         */
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');

            s.src = '//machinememos-com/embed.js';

            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>


        </div>

        <div class="col-md-4">
            <h3>Post Directory</h3>
<div id="post-directory-module">
<section class="post-directory">
    <!-- Links that trigger the jumping -->
    <!-- Added by javascript below -->
    <dl></dl>
</section>
</div>

<script type="text/javascript">

    $(document).ready(function(){
        $( "article h2" ).each(function( index ) {
            $(".post-directory dl").append("<dt><a class=\"jumper\" hre=#" +
                    $(this).attr("id")
                    + ">"
                    + $(this).text()
                    + "</a></dt>");

            var children = $(this).nextUntil("h2", "h3")

            children.each(function( index ) {
                $(".post-directory dl").append("<dd><a class=\"jumper\" hre=#" +
                        $(this).attr("id")
                        + ">"
                        + "&nbsp;&nbsp;- " + $(this).text()
                        + "</a></dd>");
            });
        });

        var fixmeTop = $('#post-directory-module').offset().top - 100;       // get initial position of the element

        $(window).scroll(function() {                  // assign scroll event listener

            var currentScroll = $(window).scrollTop(); // get current position

            if (currentScroll >= fixmeTop) {           // apply position: fixed if you
                $('#post-directory-module').css({      // scroll to that element or below it
                    top: '100px',
                    position: 'fixed',
                    width: 'inherit'
                });
            } else {                                   // apply position: static
                $('#post-directory-module').css({      // if you scroll above it
                    position: 'inherit',
                    width: 'inherit'
                });
            }

        });

        $("a.jumper").on("click", function( e ) {

            e.preventDefault();

            $("body, html").animate({
                scrollTop: ($( $(this).attr('hre') ).offset().top - 100)
            }, 600);

        });
    });

</script>
        </div>
        

    </div>

</article>

        </div>

    <footer class="container">

    <div class="site-footer">

        <div class="copyright pull-left">
            <!-- 请不要更改这一行 方便其他人知道模板的来源 谢谢 -->
            <!-- Please keep this line to let others know where this theme comes from. Thank you :D -->
            Power by <a href="https://github.com/DONGChuan/Yummy-Jekyll">Yummy Jekyll</a>
        </div>

        <a href="https://github.com/DONGChuan" target="_blank" aria-label="view source code">
            <span class="mega-octicon octicon-mark-github" title="GitHub"></span>
        </a>

        <div class="pull-right">
            <a href="javascript:window.scrollTo(0,0)" >TOP</a>
        </div>

    </div>

    <!-- Third-Party JS -->
    <script type="text/javascript" src="/bower_components/geopattern/js/geopattern.min.js"></script>

    <!-- My JS -->
    <script type="text/javascript" src="/assets/js/script.js"></script>

    

    
    <!-- Google Analytics -->
    <div style="display:none">
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-26182347-1', 'auto');
            ga('send', 'pageview');

        </script>
    </div>
    

</footer>


    </body>

</html>
