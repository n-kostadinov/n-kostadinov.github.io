<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Favicon Icon -->
    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.png">

    <title>Image classification with stacked InceptionV3</title>
    <meta name="description"
          content="Google, Microsoft, and other vendors have been training very complex, state of the art Convolutional Neural Networks on massive datasets. “Transfer learning”...">

    <link rel="canonical" href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/xgboost/ridgeregression/sklearn/tensorflow/image%20classification/imagenet/2017/05/11/cnn-image-classification-cifar-10-stacked-inceptionV3.html">
    <link rel="alternate" type="application/rss+xml" title="Blog" href="http://machinememos.com/feed.xml">

    <script type="text/javascript" src="/bower_components/jquery/dist/jquery.min.js"></script>

    <!-- Third-Party CSS -->
    <link rel="stylesheet" href="/bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="/bower_components/octicons/octicons/octicons.css">
    <link rel="stylesheet" href="/bower_components/hover/css/hover-min.css">
    <link rel="stylesheet" href="/bower_components/primer-markdown/dist/user-content.min.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- My CSS -->
    <link rel="stylesheet" href="/assets/css/common.css">

    <!-- CSS set in page -->
    

    <!-- CSS set in layout -->
    
    <link rel="stylesheet" href="/assets/css/sidebar-post-nav.css">
    

    <script type="text/javascript" src="/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>

</head>


    <body>

    <header class="site-header">
    <div class="container">
        <a id="site-header-brand" href="/" title="MACHINE MEMOS">
			<div class="media">
    			<span class="media-left">
        			<img src="/assets/images/machine_memos_logo.svg" onerror="this.onerror=null; this.src='/assets/images/machine_memos_logo.png'" class="img-responsive" style="max-width: 1em;">
    			</span>
    			<div class="media-body" style="max-width:9em; vertical-align: middle;">
        			MACHINE MEMOS
				</div>
			</div>
			</a>
        <nav class="site-header-nav" role="navigation">
            
            <a href="/"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="BLOG">
                BLOG
            </a>
            
            <a href="/code"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="CODE">
                CODE
            </a>
            
            <a href="/timeline"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="TIMELINE">
                TIMELINE
            </a>
            
            <a href="/about"
               class=" site-header-nav-item hvr-underline-from-center"
               target=""
               title="ABOUT">
                ABOUT
            </a>
            
        </nav>
    </div>
</header>


        <div class="content">
            <section class="jumbotron geopattern" data-pattern-id="Image classification with stacked InceptionV3">
    <div class="container">
        <div id="jumbotron-meta-info">
            <h1>Image classification with stacked InceptionV3</h1>
            <span class="meta-info">
                
                 
                <span class="octicon octicon-calendar"></span> 2017/05/11
                
				
					by Nikolay Kostadinov
				
            </span>
        </div>
    </div>
</section>
<script>
    $(document).ready(function(){

        $('.geopattern').each(function(){
            $(this).geopattern($(this).data('pattern-id'), {color:"#337ab7"});
        });

    });
</script>
<article class="post container" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="row">

        
        <div class="col-md-8 markdown-body">

            <p>Google, Microsoft, and other vendors have been training very complex, state of the art Convolutional Neural Networks on massive datasets. “Transfer learning” is a very powerful bundle of techniques for reusing these already fully-trained neural networks for classification of images that can be more or less different from the images that have been used in the process of training those networks.  While I explored “fine-tuning” of a neural network in my previous post, in this post I will take a CNN pre-trained on ImageNet, treat it as a fixed feature extractor for the new dataset. The features can be then fed to another, second level classifier.</p>

<h1 id="image-classification-with-stacked-googlelenet">Image Classification with stacked GoogleLeNet</h1>

<p>This post builds on my two previous posts: <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/dropout/image%20classification/2017/04/23/convolutional-neural-network-from-scratch.html">Convolutional neural network for image classification from scratch</a> and <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/tensorflow/dropout/image%20classification/2017/05/04/cnn-image-classification-cifar-10-inceptionV3.html">Image classification with pre-trained CNN InceptionV3</a>. In <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/dropout/image%20classification/2017/04/23/convolutional-neural-network-from-scratch.html">Convolutional neural network for image classification from scratch</a> I built a small convolutional neural network (CNN) to classify images from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a>. My goal was to demonstrate how easy one can construct a neural network with decent accuracy (around 67%). Achieving an accuracy higher than that would require a deeper and wider neural network. Unfortunately, deeper and wider networks are often trained on multiple GPUs for several weeks. Hence, instead of training such a CNN from scratch in <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/tensorflow/dropout/image%20classification/2017/05/04/cnn-image-classification-cifar-10-inceptionV3.html">Image classification with pre-trained CNN InceptionV3</a> I showed how one could reuse an existing already pre-trained one. Indeed, I used GoogleLeNet and more specifically the InceptionV3 neural network and applied some “finetuning” by training only the last few layers of the neural network. As a matter of fact, I was able to reach an accuracy that is significantly higher - 79,85%. In this post I want to try another approach. The goal is to achieve similar and possibly higher accuracy in much less time and without applying any fine-tuning. So, instead of retraining the last few layers, the neural network can be put in a classifier stack as a first level classifier, so that its output is the input of a second level classifier. Continue reading below for more details.</p>

<h2 id="cifar-10-image-dataset">Cifar-10 Image Dataset</h2>

<p>If you are already familiar with any of my previous posts about convolutional neural networks - <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/dropout/image%20classification/2017/04/23/convolutional-neural-network-from-scratch.html">Convolutional neural network for image classification from scratch</a> or <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/tensorflow/dropout/image%20classification/2017/05/04/cnn-image-classification-cifar-10-inceptionV3.html">Image classification with pre-trained CNN InceptionV3</a>, you might want to skip the next sections and go directly to <strong>Stacking InceptionV3</strong>.</p>

<p>The <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a> consists of 60000 32x32 color images in 10 categories - airplanes, dogs, cats, and other objects. The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. Here are the classes in the dataset, as well as 10 random images from each:</p>

<p><img src="/assets/images/dataset_overview.jpg" alt="png" /></p>

<p>The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. “Automobile” includes sedans, SUVs, things of that sort. “Truck” includes only big trucks. Neither includes pickup trucks.</p>

<h2 id="download-the-dataset">Download the dataset</h2>
<p>First, few lines of code will download the <a href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">CIFAR-10 dataset for python</a>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># DOWNLOAD DATASET </span>
<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">tarfile</span>

<span class="k">class</span> <span class="nc">DLProgress</span><span class="p">(</span><span class="n">tqdm</span><span class="p">):</span>
    <span class="n">last_block</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">=</span> <span class="n">total_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">block_num</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span> <span class="o">=</span> <span class="n">block_num</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="s">'cifar-10-python.tar.gz'</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">DLProgress</span><span class="p">(</span><span class="n">unit</span><span class="o">=</span><span class="s">'B'</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s">'CIFAR-10 Dataset'</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">urlretrieve</span><span class="p">(</span>
            <span class="s">'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'</span><span class="p">,</span>
            <span class="s">'cifar-10-python.tar.gz'</span><span class="p">,</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">hook</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s">'cifar-10-batches-py'</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="s">'cifar-10-python.tar.gz'</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre>
</div>

<h2 id="data-overview">Data Overview</h2>
<p>The dataset is broken into batches - this is especially useful if one is to train the network on a laptop as it will probably prevent it from running out of memory. I only had 12 GB on mine and a single batch used around 3.2 GB - it wouldn’t be possible to load everything at once. Nevertheless, the CIFAR-10 dataset consists of 5 batches, named <code class="highlighter-rouge">data_batch_1</code>, <code class="highlighter-rouge">data_batch_2</code>, etc.. Each batch contains the labels and images that are one of the following:</p>

<ul>
  <li>airplane</li>
  <li>automobile</li>
  <li>bird</li>
  <li>cat</li>
  <li>deer</li>
  <li>dog</li>
  <li>frog</li>
  <li>horse</li>
  <li>ship</li>
  <li>truck</li>
</ul>

<p>Understanding a dataset is part of making predictions on the data. Following functions can be used to view different images by changing the <code class="highlighter-rouge">batch_id</code> and <code class="highlighter-rouge">sample_id</code>. The <code class="highlighter-rouge">batch_id</code> is the id for a batch (1-5). The <code class="highlighter-rouge">sample_id</code> is the id for an image and label pair in the batch.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c"># The names of the classes in the dataset.</span>
<span class="n">CLASS_NAMES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">'airplane'</span><span class="p">,</span>
    <span class="s">'automobile'</span><span class="p">,</span>
    <span class="s">'bird'</span><span class="p">,</span>
    <span class="s">'cat'</span><span class="p">,</span>
    <span class="s">'deer'</span><span class="p">,</span>
    <span class="s">'dog'</span><span class="p">,</span>
    <span class="s">'frog'</span><span class="p">,</span>
    <span class="s">'horse'</span><span class="p">,</span>
    <span class="s">'ship'</span><span class="p">,</span>
    <span class="s">'truck'</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">def</span> <span class="nf">load_cfar10_batch</span><span class="p">(</span><span class="n">batch_id</span><span class="p">):</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'cifar-10-batches-py'</span><span class="p">,</span><span class="s">'data_batch_'</span> 
              <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">batch_id</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'latin1'</span><span class="p">)</span>

    <span class="n">features</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'data'</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'data'</span><span class="p">]),</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span>


<span class="k">def</span> <span class="nf">display_stats</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">sample_id</span><span class="p">):</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">sample_id</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'{} samples in batch {}.  {} is out of range.'</span>
              <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">sample_id</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">None</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Stats of batch {}:'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">batch_id</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Samples: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Label Counts: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)))))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'First 20 Labels: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">labels</span><span class="p">[:</span><span class="mi">20</span><span class="p">]))</span>

    <span class="n">sample_image</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">sample_id</span><span class="p">]</span>
    <span class="n">sample_label</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">sample_id</span><span class="p">]</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Example of Image {}:'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sample_id</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Image - Min Value: {} Max Value: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sample_image</span><span class="o">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">sample_image</span><span class="o">.</span><span class="nb">max</span><span class="p">()))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Image - Shape: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sample_image</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Label - Label Id: {} Name: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sample_label</span><span class="p">,</span> <span class="n">CLASS_NAMES</span><span class="p">[</span><span class="n">sample_label</span><span class="p">]))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sample_image</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p>Let’s check the first couple of images of each batch. The lines below can be easily modified to show an arbitrary image from any batch.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="o">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s">'retina'</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">for</span> <span class="n">batch_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_cfar10_batch</span><span class="p">(</span><span class="n">batch_id</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">image_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">display_stats</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">image_id</span><span class="p">)</span>

<span class="k">del</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="c"># free memory  </span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Stats of batch 1:
Samples: 10000
Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}
First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]

Example of Image 0:
Image - Min Value: 0 Max Value: 255
Image - Shape: (32, 32, 3)
Label - Label Id: 6 Name: frog
</code></pre>
</div>

<p><img src="/assets/images/output_7_1.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>Stats of batch 1:
Samples: 10000
Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}
First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]

Example of Image 1:
Image - Min Value: 5 Max Value: 254
Image - Shape: (32, 32, 3)
Label - Label Id: 9 Name: truck
</code></pre>
</div>

<p><img src="/assets/images/output_7_3.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>Stats of batch 2:
Samples: 10000
Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}
First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]

Example of Image 0:
Image - Min Value: 5 Max Value: 225
Image - Shape: (32, 32, 3)
Label - Label Id: 1 Name: automobile
</code></pre>
</div>

<p><img src="/assets/images/output_7_5.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>Stats of batch 2:
Samples: 10000
Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}
First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]

Example of Image 1:
Image - Min Value: 2 Max Value: 247
Image - Shape: (32, 32, 3)
Label - Label Id: 6 Name: frog
</code></pre>
</div>

<p><img src="/assets/images/output_7_7.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>Stats of batch 3:
Samples: 10000
Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}
First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]

Example of Image 0:
Image - Min Value: 0 Max Value: 254
Image - Shape: (32, 32, 3)
Label - Label Id: 8 Name: ship
</code></pre>
</div>

<p><img src="/assets/images/output_7_9.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>Stats of batch 3:
Samples: 10000
Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}
First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]

Example of Image 1:
Image - Min Value: 15 Max Value: 249
Image - Shape: (32, 32, 3)
Label - Label Id: 5 Name: dog
</code></pre>
</div>

<p><img src="/assets/images/output_7_11.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>Stats of batch 4:
Samples: 10000
Label Counts: {0: 1003, 1: 963, 2: 1041, 3: 976, 4: 1004, 5: 1021, 6: 1004, 7: 981, 8: 1024, 9: 983}
First 20 Labels: [0, 6, 0, 2, 7, 2, 1, 2, 4, 1, 5, 6, 6, 3, 1, 3, 5, 5, 8, 1]

Example of Image 0:
Image - Min Value: 34 Max Value: 203
Image - Shape: (32, 32, 3)
Label - Label Id: 0 Name: airplane
</code></pre>
</div>

<p><img src="/assets/images/output_7_13.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>Stats of batch 4:
Samples: 10000
Label Counts: {0: 1003, 1: 963, 2: 1041, 3: 976, 4: 1004, 5: 1021, 6: 1004, 7: 981, 8: 1024, 9: 983}
First 20 Labels: [0, 6, 0, 2, 7, 2, 1, 2, 4, 1, 5, 6, 6, 3, 1, 3, 5, 5, 8, 1]

Example of Image 1:
Image - Min Value: 0 Max Value: 246
Image - Shape: (32, 32, 3)
Label - Label Id: 6 Name: frog
</code></pre>
</div>

<p><img src="/assets/images/output_7_15.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>Stats of batch 5:
Samples: 10000
Label Counts: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}
First 20 Labels: [1, 8, 5, 1, 5, 7, 4, 3, 8, 2, 7, 2, 0, 1, 5, 9, 6, 2, 0, 8]

Example of Image 0:
Image - Min Value: 2 Max Value: 255
Image - Shape: (32, 32, 3)
Label - Label Id: 1 Name: automobile
</code></pre>
</div>

<p><img src="/assets/images/output_7_17.png" alt="png" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>Stats of batch 5:
Samples: 10000
Label Counts: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}
First 20 Labels: [1, 8, 5, 1, 5, 7, 4, 3, 8, 2, 7, 2, 0, 1, 5, 9, 6, 2, 0, 8]

Example of Image 1:
Image - Min Value: 1 Max Value: 244
Image - Shape: (32, 32, 3)
Label - Label Id: 8 Name: ship
</code></pre>
</div>

<p><img src="/assets/images/output_7_19.png" alt="png" /></p>

<h1 id="converting-datasets-to-tfrecord">Converting datasets to .tfrecord</h1>
<p>Next, we convert the datasets to tfrecords. This would allow for the easier further processing by Tensorflow. While the neural network constructed in <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/dropout/image%20classification/2017/04/23/convolutional-neural-network-from-scratch.html">Convolutional neural network for image classification from scratch</a> expected images with size 32x32, the CNN we are going to use here expects an input size of 299x299. Nevertheless, it is not necessary to convert all 60000 images to the target size of 299x299 as this would require much more of your disk space. Converting the data to tfrecord would actually shrink the dataset size (lossless compression) and allow for the use of tensorflow’s preprocessing pipeline and a dynamic conversion to the desired target size of 299x299 at training time.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">dataset_utils</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="n">IMAGE_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">RGB_CHANNELS</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">def</span> <span class="nf">add_to_tfrecord</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">tfrecord_writer</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'latin1'</span><span class="p">)</span>
    
    <span class="n">images</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'data'</span><span class="p">]</span>
    <span class="n">num_images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">num_images</span><span class="p">,</span> <span class="n">RGB_CHANNELS</span><span class="p">,</span> <span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="n">IMAGE_SIZE</span><span class="p">))</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="n">image_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="n">encoded_image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">encode_png</span><span class="p">(</span><span class="n">image_placeholder</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="s">''</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_images</span><span class="p">):</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">'</span><span class="se">\r</span><span class="s">&gt;&gt; Reading file [</span><span class="si">%</span><span class="s">s] image </span><span class="si">%</span><span class="s">d/</span><span class="si">%</span><span class="s">d'</span> <span class="o">%</span> \
                    <span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">num_images</span><span class="p">))</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

                <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">j</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
                <span class="n">label</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

                <span class="n">png_string</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">encoded_image</span><span class="p">,</span>\
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">image_placeholder</span><span class="p">:</span> <span class="n">image</span><span class="p">})</span>

                <span class="n">example</span> <span class="o">=</span> <span class="n">dataset_utils</span><span class="o">.</span><span class="n">image_to_tfexample</span><span class="p">(</span>\
                    <span class="n">png_string</span><span class="p">,</span> <span class="s">'png'</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">),</span> <span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
                <span class="n">tfrecord_writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">num_images</span>


<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s">'tfrecord'</span><span class="p">):</span>
    <span class="c"># make the directory</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s">'tfrecord'</span><span class="p">)</span>
    <span class="c"># write all 5 batches into single training tfrecord</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">python_io</span><span class="o">.</span><span class="n">TFRecordWriter</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'tfrecord'</span><span class="p">,</span> <span class="s">'cifar-10-training-tfrecord'</span><span class="p">))</span> <span class="k">as</span> <span class="n">tfrecord_writer</span><span class="p">:</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">):</span> <span class="c"># Train batches are data_batch_1 ... data_batch_5</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'cifar-10-batches-py'</span><span class="p">,</span> <span class="s">'data_batch_</span><span class="si">%</span><span class="s">d'</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">))</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">add_to_tfrecord</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">tfrecord_writer</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span>

    <span class="c"># Next, process the testing data:</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">python_io</span><span class="o">.</span><span class="n">TFRecordWriter</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'tfrecord'</span><span class="p">,</span> <span class="s">'cifar-10-test-tfrecord'</span><span class="p">))</span> <span class="k">as</span> <span class="n">tfrecord_writer</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'cifar-10-batches-py'</span><span class="p">,</span> <span class="s">'test_batch'</span><span class="p">)</span>
        <span class="n">add_to_tfrecord</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">tfrecord_writer</span><span class="p">)</span>

    <span class="c"># Finally, write the labels file:</span>
    <span class="n">labels_to_class_names</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">CLASS_NAMES</span><span class="p">)),</span> <span class="n">CLASS_NAMES</span><span class="p">))</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">Open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'tfrecord'</span><span class="p">,</span> <span class="s">'labels.txt'</span><span class="p">),</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels_to_class_names</span><span class="p">:</span>
            <span class="n">class_name</span> <span class="o">=</span> <span class="n">labels_to_class_names</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">'</span><span class="si">%</span><span class="s">d:</span><span class="si">%</span><span class="s">s</span><span class="se">\n</span><span class="s">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">class_name</span><span class="p">))</span>
</code></pre>
</div>

<h2 id="downloading-googlelenet">Downloading GoogleLeNet</h2>
<p>Check my previous post <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/tensorflow/dropout/image%20classification/2017/05/04/cnn-image-classification-cifar-10-inceptionV3.html">Image classification with pre-trained CNN InceptionV3</a> for information on why InceptionV3 has been selected.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">inceptionv3_archive</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'model'</span><span class="p">,</span> <span class="s">'inception_v3_2016_08_28.tar.gz'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DLProgress</span><span class="p">(</span><span class="n">tqdm</span><span class="p">):</span>
    <span class="n">last_block</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">=</span> <span class="n">total_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">block_num</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span> <span class="o">=</span> <span class="n">block_num</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s">'model'</span><span class="p">):</span>
    <span class="c"># create directory to store model</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s">'model'</span><span class="p">)</span>
    <span class="c"># download the model</span>
    <span class="k">with</span> <span class="n">DLProgress</span><span class="p">(</span><span class="n">unit</span><span class="o">=</span><span class="s">'B'</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s">'InceptionV3'</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">urlretrieve</span><span class="p">(</span>
            <span class="c"># I hope this url stays there</span>
            <span class="s">'http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz'</span><span class="p">,</span>
            <span class="n">inceptionv3_archive</span><span class="p">,</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">hook</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">inceptionv3_archive</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s">'model'</span><span class="p">)</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre>
</div>

<p>Next, we define a couple of utility functions for loading a batch and loading the dataset…</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">inception_preprocessing</span>

<span class="k">def</span> <span class="nf">load_batch</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">data_provider</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">dataset_data_provider</span><span class="o">.</span><span class="n">DatasetDataProvider</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span> <span class="n">common_queue_capacity</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">common_queue_min</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">image_raw</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">data_provider</span><span class="o">.</span><span class="n">get</span><span class="p">([</span><span class="s">'image'</span><span class="p">,</span> <span class="s">'label'</span><span class="p">])</span>
    
    <span class="c"># Preprocess image for usage by Inception.</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">inception_preprocessing</span><span class="o">.</span><span class="n">preprocess_image</span><span class="p">(</span>
        <span class="n">image_raw</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="n">is_training</span><span class="p">)</span>
    
    <span class="c"># Preprocess the image for display purposes.</span>
    <span class="n">image_raw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image_raw</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">image_raw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize_images</span><span class="p">(</span><span class="n">image_raw</span><span class="p">,</span> <span class="p">[</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">])</span>
    <span class="n">image_raw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image_raw</span><span class="p">)</span>

    <span class="c"># Batch it up.</span>
    <span class="n">images</span><span class="p">,</span> <span class="n">images_raw</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
          <span class="p">[</span><span class="n">image</span><span class="p">,</span> <span class="n">image_raw</span><span class="p">,</span> <span class="n">label</span><span class="p">],</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
          <span class="n">num_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">capacity</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">images</span><span class="p">,</span> <span class="n">images_raw</span><span class="p">,</span> <span class="n">labels</span>

<span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="n">dataset_file_name</span><span class="p">,</span> <span class="n">train_sample_size</span><span class="p">):</span>

    <span class="n">ITEMS_TO_DESCRIPTIONS</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'image'</span><span class="p">:</span> <span class="s">'A [32 x 32 x 3] color image.'</span><span class="p">,</span>
        <span class="s">'label'</span><span class="p">:</span> <span class="s">'A single integer between 0 and 9'</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">keys_to_features</span> <span class="o">=</span> <span class="p">{</span>
          <span class="s">'image/encoded'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">((),</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="s">''</span><span class="p">),</span>
          <span class="s">'image/format'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">((),</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="s">'png'</span><span class="p">),</span>
          <span class="s">'image/class/label'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">(</span>
              <span class="p">[],</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)),</span>
    <span class="p">}</span>

    <span class="n">items_to_handlers</span> <span class="o">=</span> <span class="p">{</span>
          <span class="s">'image'</span><span class="p">:</span> <span class="n">slim</span><span class="o">.</span><span class="n">tfexample_decoder</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span>
          <span class="s">'label'</span><span class="p">:</span> <span class="n">slim</span><span class="o">.</span><span class="n">tfexample_decoder</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="s">'image/class/label'</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="n">labels_to_names</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">CLASS_NAMES</span><span class="p">)):</span>
        <span class="n">labels_to_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">CLASS_NAMES</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">decoder</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">tfexample_decoder</span><span class="o">.</span><span class="n">TFExampleDecoder</span><span class="p">(</span><span class="n">keys_to_features</span><span class="p">,</span> <span class="n">items_to_handlers</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">slim</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span>
          <span class="n">data_sources</span><span class="o">=</span><span class="n">dataset_file_name</span><span class="p">,</span>
          <span class="n">reader</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">TFRecordReader</span><span class="p">,</span>
          <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
          <span class="n">num_samples</span><span class="o">=</span><span class="n">train_sample_size</span><span class="p">,</span>
          <span class="n">items_to_descriptions</span><span class="o">=</span><span class="n">ITEMS_TO_DESCRIPTIONS</span><span class="p">,</span>
          <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">CLASS_NAMES</span><span class="p">),</span>
          <span class="n">labels_to_names</span><span class="o">=</span><span class="n">labels_to_names</span><span class="p">)</span>
</code></pre>
</div>

<h2 id="stacking-inceptionv3">Stacking InceptionV3</h2>
<p>So instead of fine-tuning the neural network like we did in <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/tensorflow/dropout/image%20classification/2017/05/04/cnn-image-classification-cifar-10-inceptionV3.html">Image classification with pre-trained CNN InceptionV3</a>, we are going to use it as a first level classifier in a stack of classifiers consisting of two levels. In the code below the InceptionV3 model is loaded and without any training whatsoever it is used to make a prediction for all images in the training set. Note that the unmodified InceptionV3 model has an output that is a vector of length 1001. For each image this output vector is saved to be later used as un input for the second level classifier.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">inception_v3</span> <span class="kn">import</span> <span class="n">inception_v3</span>
<span class="kn">from</span> <span class="nn">inception_v3</span> <span class="kn">import</span> <span class="n">inception_v3_arg_scope</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">TRAIN_SAMPLES</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">NUMBER_OF_STEPS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">TRAIN_SAMPLES</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">INCEPTION_OUTPUT_SIZE</span> <span class="o">=</span> <span class="mi">1001</span>

<span class="n">INCEPTION_IMAGE_SIZE</span> <span class="o">=</span> <span class="mi">299</span>

<span class="n">slim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">slim</span>

<span class="n">meta_data_train_X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">meta_data_train_Y</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
    
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'tfrecord'</span><span class="p">,</span><span class="s">'cifar-10-training-tfrecord'</span><span class="p">),</span> <span class="n">TRAIN_SAMPLES</span><span class="p">)</span>
    <span class="n">images</span><span class="p">,</span> <span class="n">images_raw</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_batch</span><span class="p">(</span>
        <span class="n">train_dataset</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">INCEPTION_IMAGE_SIZE</span><span class="p">,</span> <span class="n">INCEPTION_IMAGE_SIZE</span><span class="p">)</span>
    
    <span class="c"># Create the model, use the default arg scope to configure the batch norm parameters.</span>
    <span class="k">with</span> <span class="n">slim</span><span class="o">.</span><span class="n">arg_scope</span><span class="p">(</span><span class="n">inception_v3_arg_scope</span><span class="p">()):</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">inception_v3</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">INCEPTION_OUTPUT_SIZE</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    
    <span class="n">init_fn</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">assign_from_checkpoint_fn</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'model'</span><span class="p">,</span><span class="s">'inception_v3.ckpt'</span><span class="p">),</span> <span class="n">slim</span><span class="o">.</span><span class="n">get_model_variables</span><span class="p">())</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">slim</span><span class="o">.</span><span class="n">queues</span><span class="o">.</span><span class="n">QueueRunners</span><span class="p">(</span><span class="n">sess</span><span class="p">):</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">initialize_local_variables</span><span class="p">())</span>
            <span class="n">init_fn</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">NUMBER_OF_STEPS</span><span class="p">)):</span>
                <span class="n">np_probabilities</span><span class="p">,</span> <span class="n">np_images_raw</span><span class="p">,</span> <span class="n">np_labels</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">images_raw</span><span class="p">,</span> <span class="n">labels</span><span class="p">])</span>
                <span class="n">meta_data_train_X</span> <span class="o">+=</span> <span class="n">np_probabilities</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="n">meta_data_train_Y</span> <span class="o">+=</span> <span class="n">np_labels</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>100%|██████████| 1000/1000 [3:00:56&lt;00:00, 10.95s/it] 
</code></pre>
</div>

<p>It does not hurt to save the outputs to the disk in case the python notebook kernel crashes…</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pickle</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">)</span> <span class="o">==</span> <span class="n">TRAIN_SAMPLES</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">meta_data_train_Y</span><span class="p">)</span> <span class="o">==</span> <span class="n">TRAIN_SAMPLES</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'meta_data_train_inceptionV3.p'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">((</span><span class="n">meta_data_train_X</span><span class="p">,</span> <span class="n">meta_data_train_Y</span><span class="p">),</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'meta_data_train_inceptionV3.p'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
    <span class="n">meta_data_train_X</span><span class="p">,</span> <span class="n">meta_data_train_Y</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</code></pre>
</div>

<p>Once training data set goes through the InceptionV3 network, you are all set to use the output vectors that have been produced as a training set for a second level classifier, Hence, your next task is to choose the second level classifier. As an input it receives the output vectors created by the unmodified InceptionV3 neural network. Its output, however, is the actual label - an integer from 1 to 10 for the 10 categories in the cifar-10 dataset. Below I will train three different second level classifiers in order to compare their performance. I will start with the most simple classifier possible, linear regression with L2 regularization, that is also known as <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html">ridge regression classifier</a>. It is not a bad idea to use a 5-fold cross validation in order to evaluate the classifier’s accuracy without actually using the test set.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">ridge_classifier</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">ridge_classifier</span><span class="p">,</span> <span class="n">meta_data_train_X</span><span class="p">,</span> <span class="n">meta_data_train_Y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy ridge classifier'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Accuracy ridge classifier 0.743219828872
</code></pre>
</div>

<p>With an accuracy of over 74%, it is already better than the accuracy achieved in my homemade, small and simple CNN described in <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/dropout/image%20classification/2017/04/23/convolutional-neural-network-from-scratch.html">Convolutional neural network for image classification from scratch</a>. Let’s train the ridge regression on the whole training set, it only takes a few seconds…</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">ridge_classifier</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">,</span> <span class="n">meta_data_train_Y</span><span class="p">)</span>
</code></pre>
</div>

<p>The second second-level classifier I want to evaluate is a small fully connected neural network. We can split the training set into training (90%) and validation (10%) parts in order to test the classifier’s performance without actually using the test set. To keep it short and simple, I will use the <a href="https://www.tensorflow.org/get_started/tflearn">TensorFlow’s high-level machine learning API (tf.contrib.learn)</a>. The neural network below has an input layer of 1001 nodes (that is the output of Inception3), and three hidden layers of 2048, 512 and 64 nodes.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">[:</span><span class="mi">45000</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">meta_data_train_Y</span><span class="p">[:</span><span class="mi">45000</span><span class="p">]</span>
<span class="n">validation_X</span><span class="p">,</span> <span class="n">validation_Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">[</span><span class="mi">45000</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">meta_data_train_Y</span><span class="p">[</span><span class="mi">45000</span><span class="p">:]</span>

<span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">infer_real_valued_columns_from_input</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span>
<span class="n">dnnClassifier</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">DNNClassifier</span><span class="p">(</span><span class="n">hidden_units</span><span class="o">=</span><span class="p">[</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
                                            <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>  
                                            <span class="n">n_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                            <span class="n">model_dir</span><span class="o">=</span><span class="s">'second_leveld_dnn'</span><span class="p">,</span>
                                            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                            <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)):</span>
    <span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">accuracy_score</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">validation_X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">validation_Y</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="s">"accuracy"</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Accuracy DNNClassifier'</span><span class="p">,</span><span class="n">accuracy_score</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code> 10%|█         | 1/10 [10:48&lt;1:37:14, 648.28s/it]

Accuracy DNNClassifier 0.7536


 20%|██        | 2/10 [21:47&lt;1:26:52, 651.62s/it]

Accuracy DNNClassifier 0.7772


 30%|███       | 3/10 [33:02&lt;1:16:50, 658.59s/it]

Accuracy DNNClassifier 0.7888


 40%|████      | 4/10 [43:58&lt;1:05:47, 657.90s/it]

Accuracy DNNClassifier 0.797


 50%|█████     | 5/10 [54:30&lt;54:10, 650.17s/it]  

Accuracy DNNClassifier 0.8022


 60%|██████    | 6/10 [1:05:08&lt;43:05, 646.26s/it]

Accuracy DNNClassifier 0.8062


 70%|███████   | 7/10 [1:16:01&lt;32:25, 648.52s/it]

Accuracy DNNClassifier 0.808


 80%|████████  | 8/10 [1:27:10&lt;21:49, 654.67s/it]

Accuracy DNNClassifier 0.8082


 90%|█████████ | 9/10 [1:38:04&lt;10:54, 654.31s/it]

Accuracy DNNClassifier 0.8072


100%|██████████| 10/10 [1:48:54&lt;00:00, 653.14s/it]

Accuracy DNNClassifier 0.808
</code></pre>
</div>

<p>The accuracy goes up to almost 81%. However, a little more than a few seconds are needed. It took almost 2 hours on my laptop. And then we need another two hours to train it on the whole training set… I will be gearing up with several GPUs in the next few weeks.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">infer_real_valued_columns_from_input</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span>
<span class="n">dnnClassifier</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">DNNClassifier</span><span class="p">(</span><span class="n">hidden_units</span><span class="o">=</span><span class="p">[</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
                                            <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>  
                                            <span class="n">n_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                            <span class="n">model_dir</span><span class="o">=</span><span class="s">'full_second_leveld_dnn'</span><span class="p">,</span>
                                            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                            <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)):</span>
    <span class="n">dnnClassifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">y</span><span class="o">=</span><span class="n">meta_data_train_Y</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>100%|██████████| 10/10 [2:11:16&lt;00:00, 749.81s/it] 
</code></pre>
</div>

<p>At last, I want to also evaluate one more classifier. This one is actually one of mine and many AI engineers favorite - the Boosted Trees classifier and its implementation <a href="http://xgboost.readthedocs.io/en/latest/model.html">xgboost</a>. It became widely popular as it was consistently used in the winning solutions for many of the challenges posted on <a href="http://xgboost.readthedocs.io/en/latest/model.html">kaggle</a>. Interesting enough, several challenges has been won by using only feature engineering and stacking xgboost classifier on top of each other… Sadly, you can not really classify images with Boosted Trees, but you can sure use them as a second level classifier.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">xgboost</span>

<span class="n">xgb_classifier</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">xgb_classifier</span><span class="p">,</span>  <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_Y</span><span class="p">),</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy xgboost'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Accuracy xgboost 0.823939567637


[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 71.9min finished
</code></pre>
</div>

<p>In a 5-fold cross validation set it yields the best accuracy so far more than 82%. It also needs a little less time than the fully connected neural network above. Let’s train it on the whole training set.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># Prepare classifier</span>
<span class="n">xgb_classifier</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_train_Y</span><span class="p">))</span>
</code></pre>
</div>

<h2 id="evaluation">Evaluation</h2>
<p>At last, it is time to evaluate our two level stack. First, we move all the images from the test set through the neural network to create the output of the first layer of our two layer stack. That output we are then to feed into each of the second level classifiers in order to get the final predictions.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">TEST_SAMPLES</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">NUMBER_OF_STEPS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">TEST_SAMPLES</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>

<span class="n">meta_data_test_X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">meta_data_test_Y</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
    
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'tfrecord'</span><span class="p">,</span><span class="s">'cifar-10-test-tfrecord'</span><span class="p">),</span> <span class="n">TEST_SAMPLES</span><span class="p">)</span>
    <span class="n">images</span><span class="p">,</span> <span class="n">images_raw</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_batch</span><span class="p">(</span>
        <span class="n">test_dataset</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">INCEPTION_IMAGE_SIZE</span><span class="p">,</span> <span class="n">INCEPTION_IMAGE_SIZE</span><span class="p">)</span>
    
    <span class="c"># Create the model, use the default arg scope to configure the batch norm parameters.</span>
    <span class="k">with</span> <span class="n">slim</span><span class="o">.</span><span class="n">arg_scope</span><span class="p">(</span><span class="n">inception_v3_arg_scope</span><span class="p">()):</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">inception_v3</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">INCEPTION_OUTPUT_SIZE</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    
    <span class="n">init_fn</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">assign_from_checkpoint_fn</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s">'model'</span><span class="p">,</span><span class="s">'inception_v3.ckpt'</span><span class="p">),</span> <span class="n">slim</span><span class="o">.</span><span class="n">get_model_variables</span><span class="p">())</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">slim</span><span class="o">.</span><span class="n">queues</span><span class="o">.</span><span class="n">QueueRunners</span><span class="p">(</span><span class="n">sess</span><span class="p">):</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">initialize_local_variables</span><span class="p">())</span>
            <span class="n">init_fn</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">NUMBER_OF_STEPS</span><span class="p">)):</span>
                <span class="n">np_probabilities</span><span class="p">,</span> <span class="n">np_images_raw</span><span class="p">,</span> <span class="n">np_labels</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">images_raw</span><span class="p">,</span> <span class="n">labels</span><span class="p">])</span>
                <span class="n">meta_data_test_X</span> <span class="o">+=</span> <span class="n">np_probabilities</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="n">meta_data_test_Y</span> <span class="o">+=</span> <span class="n">np_labels</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>100%|██████████| 200/200 [38:55&lt;00:00, 10.25s/it] 
</code></pre>
</div>

<p>Ok, now the outputs are used as inputs in the three classifiers - ridge regression, fully connected NN and xgboost. The final accuracy is then calculated for each of the three classifiers.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="c"># Accuracy of Ridge Regression as second level classifier, evaluated on the test set</span>
<span class="n">predictions_ridge</span> <span class="o">=</span> <span class="n">ridge_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">meta_data_test_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy with RidgeRegression as second level classifier'</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">predictions_ridge</span><span class="p">,</span> <span class="n">meta_data_test_Y</span><span class="p">))</span>
<span class="n">prediction_dnn</span> <span class="o">=</span> <span class="n">dnnClassifier</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_test_X</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy with Deep Neural Network as second level classifier'</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">prediction_dnn</span><span class="p">),</span> <span class="n">meta_data_test_Y</span><span class="p">))</span>
<span class="n">prediction_xgb</span> <span class="o">=</span> <span class="n">xgb_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">meta_data_test_X</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy with XGB as second level classifier'</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction_xgb</span><span class="p">,</span> <span class="n">meta_data_test_Y</span><span class="p">))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Accuracy with RidgeRegression as second level classifier 0.7357
Accuracy with Deep Neural Network as second level classifier 0.7977
Accuracy with XGB as second level classifier 0.8176
</code></pre>
</div>

<p>Yet again, xgboost did not disappoint and yield the best accuracy of three classifiers. Let’s save it for later use.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'xgboost_model.p'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">xgb_classifier</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
</code></pre>
</div>

<h2 id="outlook">Outlook</h2>

<p>It may seem counterintuitive that the classifier stack produced better results than the fine-tuning approach shown in <a href="http://machinememos.com/python/artificial%20intelligence/machine%20learning/cifar10/neural%20networks/convolutional%20neural%20network/googlelenet/inception/tensorflow/dropout/image%20classification/2017/05/04/cnn-image-classification-cifar-10-inceptionV3.html">Image classification with pre-trained CNN InceptionV3</a> An explanation is given in the chapter <a href="http://cs231n.github.io/transfer-learning/">Transfer Learning</a> in Andrej Karpathy’s lecture <a href="http://cs231n.github.io/">CS231n: Convolutional Neural Networks for Visual Recognition</a>. “New dataset is small and similar to original dataset. Since the data is small, it is not a good idea to fine-tune the ConvNet due to overfitting concerns. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.” Well, the Cifar-10 is indeed similar to the ImageNet dataset, but is it small? With 50,000 images in the training set, it does not seem so. But in comparison to the massive <a href="http://image-net.org/index">ImageNet</a> with over 10,000,000 images, it is rather tiny. So what is next? Deploying both stacked models into a web application and making it possible to actually upload and classify a picture. As always feel free to checkout the whole github repository: <a href="https://github.com/n-kostadinov/cnn-image-classification-stacked-inception3">cnn-image-classification-stacked-inception3</a>.</p>


            <!-- Comments -->
            
<div class="comments">
    <div id="disqus_thread"></div>
    <script>
        /**
         * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
         * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
         */
        /*
         var disqus_config = function () {
         this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
         this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
         };
         */
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');

            s.src = '//machinememos-com/embed.js';

            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>


        </div>

        <div class="col-md-4">
            <h3>Post Directory</h3>
<div id="post-directory-module">
<section class="post-directory">
    <!-- Links that trigger the jumping -->
    <!-- Added by javascript below -->
    <dl></dl>
</section>
</div>

<script type="text/javascript">

    $(document).ready(function(){
        $( "article h2" ).each(function( index ) {
            $(".post-directory dl").append("<dt><a class=\"jumper\" hre=#" +
                    $(this).attr("id")
                    + ">"
                    + $(this).text()
                    + "</a></dt>");

            var children = $(this).nextUntil("h2", "h3")

            children.each(function( index ) {
                $(".post-directory dl").append("<dd><a class=\"jumper\" hre=#" +
                        $(this).attr("id")
                        + ">"
                        + "&nbsp;&nbsp;- " + $(this).text()
                        + "</a></dd>");
            });
        });

        var fixmeTop = $('#post-directory-module').offset().top - 100;       // get initial position of the element

        $(window).scroll(function() {                  // assign scroll event listener

            var currentScroll = $(window).scrollTop(); // get current position

            if (currentScroll >= fixmeTop) {           // apply position: fixed if you
                $('#post-directory-module').css({      // scroll to that element or below it
                    top: '100px',
                    position: 'fixed',
                    width: 'inherit'
                });
            } else {                                   // apply position: static
                $('#post-directory-module').css({      // if you scroll above it
                    position: 'inherit',
                    width: 'inherit'
                });
            }

        });

        $("a.jumper").on("click", function( e ) {

            e.preventDefault();

            $("body, html").animate({
                scrollTop: ($( $(this).attr('hre') ).offset().top - 100)
            }, 600);

        });
    });

</script>
        </div>
        

    </div>

</article>

        </div>

    <footer class="container">

    <div class="site-footer">

        <div class="copyright pull-left">
            <!-- 请不要更改这一行 方便其他人知道模板的来源 谢谢 -->
            <!-- Please keep this line to let others know where this theme comes from. Thank you :D -->
            Power by <a href="https://github.com/DONGChuan/Yummy-Jekyll">Yummy Jekyll</a>
        </div>

        <a href="https://github.com/DONGChuan" target="_blank" aria-label="view source code">
            <span class="mega-octicon octicon-mark-github" title="GitHub"></span>
        </a>

        <div class="pull-right">
            <a href="javascript:window.scrollTo(0,0)" >TOP</a>
        </div>

    </div>

    <!-- Third-Party JS -->
    <script type="text/javascript" src="/bower_components/geopattern/js/geopattern.min.js"></script>

    <!-- My JS -->
    <script type="text/javascript" src="/assets/js/script.js"></script>

    

    
    <!-- Google Analytics -->
    <div style="display:none">
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-26182347-1', 'auto');
            ga('send', 'pageview');

        </script>
    </div>
    

</footer>


    </body>

</html>
